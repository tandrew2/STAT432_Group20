---
title: 'STAT 432 Group Project'
subtitle: 'Best Wine Ever Company: How good is the wine?'
author: "Group 20 | Theodore Andrew (tandrew2) | Alicia Lo (tlo8) | Sumit Patel (snpatel5)"
abstract: 'Abstract should be inserted here'
output: 
  html_document: 
    theme: simplex
    toc: yes
---

# Introduction

## Goal and motivation 
Hiring experts to rate the quality of wine can be a huge expense for wine brewers, and it makes brewing new wine risky if brewers do not have an idea of what the outcome would be like since they will need to spend money on both the ingredients and the ratings. Therefore, we decide to analyze a wine dataset and make predictions with the analysis. Using the models from our analysis, brewers can predict the quality of wine based on different variables that affect wineâ€™s quality and would be able to adjust the ingredient or conditions before actually brewing new wine and also know the predicted quality of the new wine. Brewers would not need to find experts every time they test out new wine and will also save a lot of money and time from having fewer trial and errors.

## Data

We decided to analyze the wine dataset from [this website](`http://archive.ics.uci.edu/ml/datasets/Wine+Quality`). This dataset contains red and white vinho verde wine samples, from the north of Portugal. The dataset records information from different physicochemical tests done on the wine. We want to be able to use the different attributes recorded for wine and predict the quality of the wine on a scale of 1 to 10. This dataset includes 13 variables which are further explained in the data dictionary of the appendix. 

The dataset contains 6497 observations, with 1599 red wine observations and 4898 white wine observations. All variables are numeric variables except **category** which is the only factor variable. Variable **quality** ranges from 0 to 10 and will be the response for our **regression** prediction. 

Fixed acidity in wine includes tartaric, malic, citric, and succinic acid. Volatile acidity in wine includes acetic acid, lactic, formic, butyric, and propionic acids. The unit of acidity is grams per liter (g/L). The density of wine is calculated by the mass of wine over the volume of wine, and the unit is grams per milliliter (g/ml). The percentage of residual sugar in wine is the sugar mass divided by the volume of wine, so a wine with 2\% residual sugar contains 20 grams of sugar in a liter of wine. The unit of chloride concentration is grams per liter (g/L). Sulfur dioxide is added to wine as a preservative to slow down the oxidation process and free sulfur dioxide is the sulfur dioxide that are available to react in the wine. The unit of sulfur dioxide is milligrams per liter (mg/L). Sulfates are added to wine in powder form, and the unit of sulfates is in grams per liter. The alcohol concentration of wine is in percentage of alcohol by volume. 

## EDA

```{r include = FALSE}
# general
library(MASS)
library(caret)
library(tidyverse)
library(knitr)
library(kableExtra)
library(mlbench)

# specific
library(ISLR)
library(ellipse)
library(randomForest)
library(gbm)
library(glmnet)
library(rpart)
library(rpart.plot)
library(ggplot2)
library(faraway)
library(klaR)
```

```{r include = FALSE}
wine = read.csv("wine.csv")
wine = wine[, -c(1, 2)]
```

```{r include = FALSE}
# Test-Split the data
set.seed(42)
wine_idx = createDataPartition(wine$quality, p = 0.75, list = FALSE)
wine_idx = sample(wine_idx)
wine_trn = wine[wine_idx,]
wine_tst = wine[-wine_idx,]
wine_tst = wine_tst[sample(nrow(wine_tst)),]
```

Below is a plot of the relationship between **residual.sugar** and **quality**, to help readers better understand the dataset.

```{r echo = FALSE, fig.align = "center", fig.height = 7, fig.width = 10, message = FALSE, warning = FALSE}
wine_plot = ggplot(wine) + geom_point(aes(x = residual.sugar, y = quality), size = 0.3) 
# + facet_wrap(~quality)

wine_plot
```

```{r, message = FALSE, echo = FALSE}
#histogram(wine_trn$quality)
ggplot(wine_trn, aes(quality)) + geom_histogram()
```


```{r, echo = FALSE}
wine_boost = gbm(quality ~ ., data = wine_trn, distribution = "gaussian",
                n.trees = 5000, interaction.depth = 4, shrinkage = 0.01)
summary(wine_boost)
```

Based on the plot, we see the distribution of sugar level of wine with different quality. The wine with average quality (5 - 8) have similar sugar levels. However, if we look at the wine with best quality, they do not have high sugar level, meaning that to provide higher quality, we will likely need to decrease our sugar level into acceptable amount.

# Methods

## Classification

```{r}
wine = read.csv("wine.csv")
wine = wine[,-c(1, 2)]
wine$quality = as.factor(wine$quality)
```


```{r}
# Test-split the data
set.seed(42)
wine_idx = createDataPartition(wine$quality, p = 0.75, list = FALSE)
wine_trn = wine[wine_idx,]
wine_tst = wine[-wine_idx,]
```


### Variable selection method


```{r}
y = as.numeric(wine$quality)
X = model.matrix(quality ~ ., wine)[, -12]

wine_lasso = cv.glmnet(X, y, alpha = 1)
plot(wine_lasso)
coef(wine_lasso, s = "lambda.1se")
```


### Modelling Analysis

```{r}
calc_rmse = function(actual, predicted) {
  sqrt(mean((actual - predicted) ^ 2))
}
```

### Multinomial Logistic Regression

```{r message=FALSE, warning=FALSE, include=FALSE}
wine_multi = train(quality ~ .,
                   data = wine_trn,
                   method = "multinom",
                   trControl = trainControl(method = "cv", number = 5)
                   )

multi_pred = predict(wine_multi, newdata = wine_tst)
rmse_multinom = calc_rmse(actual = as.numeric(wine_tst$quality), 
                          predicted = as.numeric(multi_pred))
```

### KNN (without scaling)

```{r}
wine_knn_wo = train(quality ~ .,
                    data = wine_trn,
                    method = "knn",
                    trControl = trainControl(method = "cv", number = 5)
                    )

pred_knn_wo = predict(wine_knn_wo, newdata = wine_tst)
rmse_knn_wo = calc_rmse(actual = as.numeric(wine_tst$quality), 
                        predicted = as.numeric(pred_knn_wo))
```

### KNN (with scaling)

```{r}
wine_knn_sc = train(quality ~ .,
                    data = wine_trn,
                    method = "knn",
                    trControl = trainControl(method = "cv", number = 5),
                    preProcess = c("center", "scale")
                    )

pred_knn_sc = predict(wine_knn_sc, newdata = wine_tst)
rmse_knn_sc = calc_rmse(actual = as.numeric(wine_tst$quality), 
                        predicted = as.numeric(pred_knn_sc))
```

### LDA

```{r message=FALSE, warning=FALSE}
class_lda_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "lda"
)

pred_lda_class = as.numeric(predict(class_lda_mod, wine_tst))
rmse_lda = calc_rmse(pred_lda_class, as.numeric(wine_tst$quality))
```

### RDA

```{r message=FALSE, warning=FALSE}
class_rda_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "rda"
)

pred_rda_class = as.numeric(predict(class_rda_mod, wine_tst))
rmse_rda = calc_rmse(pred_rda_class, as.numeric(wine_tst$quality))
```

### NB

```{r message=FALSE, warning=FALSE}
wine_nb = train(quality ~ .,
                 data = wine_trn,
                 method = "nb",
                 trControl = trainControl(method = "cv", number = 5)
                 )

nb_pred = predict(wine_nb, newdata = wine_tst)
rmse_nb = calc_rmse(actual = as.numeric(wine_tst$quality), predicted = as.numeric(nb_pred))
```

### Elastic Net

```{r message=FALSE, warning=FALSE}
wine_elnet = train(quality ~ .,
                   data = wine_trn,
                   method = "glmnet",
                   trControl = trainControl(method = "cv", number = 5)
                   )

pred_elnet = predict(wine_elnet, newdata = wine_tst)
rmse_elnet = calc_rmse(actual = as.numeric(wine_tst$quality),
                       predicted = as.numeric(pred_elnet))
```

### Tree

```{r}
wine_tree = train(quality ~ .,
                   data = wine_trn,
                   method = "rpart",
                   trControl = trainControl(method = "cv", number = 5)
                   )

pred_tree = predict(wine_tree, newdata = wine_tst)
rmse_tree = calc_rmse(actual = as.numeric(wine_tst$quality),
                      predicted = as.numeric(pred_tree))
```

### RF

```{r}
set.seed(9034)
wine_rf = train(quality ~ .,
                data = wine_trn,
                method = "rf",
                trControl = trainControl(method = "oob"),
                importance = T
                )

rf_pred = predict(wine_rf, newdata = wine_tst)
rmse_rf = calc_rmse(actual = as.numeric(wine_tst$quality), predicted = as.numeric(rf_pred))
```

### GBM

```{r message=FALSE, warning=FALSE}
set.seed(9034)
wine_gbm = train(quality ~ .,
                 data = wine_trn,
                 method = "gbm",
                 trControl = trainControl(method = "cv", number = 5),
                 verbose = F
                 )

gbm_pred = predict(wine_gbm, newdata = wine_tst)
rmse_gbm = calc_rmse(actual = as.numeric(wine_tst$quality), predicted = as.numeric(gbm_pred))
```


## Regression

```{r include = FALSE}
wine = read.csv("wine.csv")
wine = wine[, -c(1, 2)]
```

```{r include = FALSE}
# Test-Split the data
set.seed(42)
wine_idx = createDataPartition(wine$quality, p = 0.75, list = FALSE)
wine_idx = sample(wine_idx)
wine_trn = wine[wine_idx,]
wine_tst = wine[-wine_idx,]
wine_tst = wine_tst[sample(nrow(wine_tst)),]
```

### Linear Regression
```{r}
set.seed(1753)
sim_lm_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "lm"
)
```

### Random Forest
```{r}
set.seed(1753)
sim_rf_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "rf"
)
```

### KNN
```{r}
set.seed(1753)
sim_knn_mod_scale = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  preProcess = "scale",
  method = "knn"
)

```

```{r}
set.seed(1753)
sim_knn_mod_unscale = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "knn"
)
```

### Tree
```{r}
set.seed(1753)
sim_rpart_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "rpart"
)
```

```{r}
set.seed(1753)
sim_gbm_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "gbm",
  verbose = FALSE
)
```

### Elastic Net

```{r}
sim_glmnet_mod = train(
  quality ~ .,
  data = wine_trn,
  trControl = trainControl(method = "cv", number = 10),
  method = "glmnet"
)
```

# Results

## Classification
```{r echo = FALSE}
model_method = c("Multinomial Logistic Regression",
                 "KNN without scaling",
                 "KNN with scaling",
                 "LDA",
                 "RDA",
                 "Naive Bayes",
                 "Elastic Net",
                 "Tree",
                 "Random Forest",
                 "Gradient Boosted Model"
                 )

rmse_values = c(rmse_multinom, rmse_knn_wo, rmse_knn_sc, rmse_lda, rmse_rda, rmse_nb, 
                rmse_elnet, rmse_tree, rmse_rf, rmse_gbm)

class_summary = data.frame(model_method, rmse_values)
colnames(class_summary) = c("Model Method", "Testing RMSE")

kable_styling(kable(class_summary, format = "html", main = "Classification Testing RMSE", digits = 4), full_width = F)
```

## Regression

```{r, echo = FALSE}
reg_mod = list(sim_lm_mod, sim_rf_mod, sim_knn_mod_scale, sim_knn_mod_unscale, sim_rpart_mod, sim_gbm_mod, sim_glmnet_mod)
tst_pred = lapply(reg_mod, predict, wine_tst)

trn_rmse = c(sim_lm_mod$resample$RMSE, sim_rf_mod$resample$RMSE, sim_knn_mod_scale$resample$RMSE, sim_knn_mod_unscale$resample$RMSE, sim_rpart_mod$resample$RMSE, sim_gbm_mod$resample$RMSE, sim_glmnet_mod$resample$RMSE)
tst_rmse - sapply(tst_pred, calc_rmse, actual = wine_tst$quality)
```

```{r, echo = FALSE}
regression_results = data.frame(
  mod = c("Linear Regression", "Random Forest", "KNN w/ Scaling", "KNN w/o Scaling", "Tree", "Boosted Tree", "Elastic Net"),
  trn_rmse = trn_rmse,
  tst_rmse = tst_rmse
)
colnames(regression_results) = c("Model Type", "Train RMSE", "Test RMSE")
kable_styling(kable(regression_results, format = "html", digits = 5), full_width = FALSE)
```


# Discussion

# Appendix

## Data Dictionary

| Name          | Description     | Type  |
| ------------- |:-------------:  | -----:|
| fixed.acidity | most acids involved with wine or fixed or nonvolatile (do not evaporate readily) | Numeric |
| Volatile.acidity | the amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste | Numeric |
| Citric.acid | found in small quantities, citric acid can add â€˜freshnessâ€™ and flavor to wines | Numeric | 
| Residual.sugar | the amount of sugar remaining after fermentation stops, itâ€™s rare to find wines with less than 1 gram/liter and wines with greater than 45 grams/liter are considered sweet | Numeric | 
| Chlorides | the amount of salt in the wine | Numeric |
| Free.sulfur.dioxide | the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion; it prevents microbial growth and the oxidation of wine | Numeric | 
| Total.sulfur.dioxide | amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine | Numeric | 
| Density | the density of water is close to that of water depending on the percent alcohol and sugar content | Numeric | 
| pH | describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4 on the pH scale | Numeric | 
| Sulfates | a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich acts as an antimicrobial and antioxidant | Numeric |
| Alcohol | the percent alcohol content of the wine | Numeric | 
| Quality | score between 0 and 10 | Integer |
| Category | Red or White wine | Factor | 

